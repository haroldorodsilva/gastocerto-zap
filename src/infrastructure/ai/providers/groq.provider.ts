import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
// @ts-ignore - groq-sdk n√£o instalado ainda
import Groq from 'groq-sdk';
import {
  IAIProvider,
  TransactionData,
  TransactionType,
  UserContext,
  AIProviderType,
} from '../ai.interface';
import {
  getTransactionSystemPrompt,
  TRANSACTION_USER_PROMPT_TEMPLATE,
} from '../../../features/transactions/contexts/registration/prompts/transaction-extraction.prompt';

/**
 * Groq Provider - Especializado em √ÅUDIO
 *
 * VANTAGENS GROQ:
 * - Whisper GR√ÅTIS e ilimitado! üéâ
 * - Lat√™ncia ultra-baixa (5-10x mais r√°pido que OpenAI)
 * - Modelos open-source (Llama 3, Mixtral)
 * - √ìtimo para produ√ß√£o com alto volume
 *
 * CUSTO:
 * - Whisper (√°udio): GR√ÅTIS! üÜì
 * - Llama 3 70B: $0.00059 / 1K tokens (input), $0.00079 (output)
 * - Mixtral 8x7B: $0.00024 / 1K tokens (input), $0.00024 (output)
 *
 * vs OpenAI:
 * - Whisper OpenAI: $0.006 / minuto
 * - GPT-4: $0.03 / 1K tokens
 */
@Injectable()
export class GroqProvider implements IAIProvider {
  private readonly logger = new Logger(GroqProvider.name);
  private apiKey: string;
  private model: string;
  private readonly baseUrl = 'https://api.groq.com/openai/v1';
  private initialized = false;

  constructor(private configService: ConfigService) {
    // Inicializa√ß√£o ass√≠ncrona ser√° feita no primeiro uso
  }

  /**
   * Inicializa provider com configura√ß√µes do banco ou ENV
   */
  private async initialize(): Promise<void> {
    if (this.initialized) return;

    try {
      // Tentar buscar do banco primeiro
      const { PrismaService } = await import('../../../core/database/prisma.service');
      const prisma = new PrismaService();

      const providerConfig = await prisma.aIProviderConfig.findUnique({
        where: { provider: 'groq' },
      });

      if (providerConfig?.apiKey && providerConfig.enabled) {
        // Usar configura√ß√£o do banco
        this.apiKey = providerConfig.apiKey;
        this.model = providerConfig.textModel || 'llama-3.1-70b-versatile';
        this.logger.log(`‚úÖ Groq Provider inicializado via BANCO - Modelo: ${this.model}`);
        this.logger.log(`üé§ Whisper GR√ÅTIS dispon√≠vel!`);
      } else {
        // Fallback para ENV (apenas dev)
        this.apiKey = this.configService.get<string>('ai.groq.apiKey', '');
        this.model = this.configService.get<string>('ai.groq.model', 'llama-3.1-70b-versatile');

        if (this.apiKey) {
          this.logger.warn('‚ö†Ô∏è  Groq usando ENV (configure no banco para produ√ß√£o)');
          this.logger.log(`üé§ Whisper GR√ÅTIS dispon√≠vel!`);
        } else {
          this.logger.warn('‚ö†Ô∏è  Groq API Key n√£o configurada - Provider desabilitado');
        }
      }

      this.initialized = true;
    } catch (error) {
      this.logger.error('Erro ao inicializar Groq:', error.message);
      this.initialized = true;
    }
  }

  /**
   * Verifica se o provider est√° dispon√≠vel
   */
  private async isAvailable(): Promise<boolean> {
    await this.initialize();
    return !!this.apiKey;
  }

  /**
   * Extrai transa√ß√£o de texto usando Llama 3 ou Mixtral
   */
  async extractTransaction(text: string, userContext?: UserContext): Promise<TransactionData> {
    if (!(await this.isAvailable())) {
      throw new Error('Groq Provider n√£o est√° dispon√≠vel (API Key n√£o configurada)');
    }

    try {
      const startTime = Date.now();
      this.logger.debug(`[Groq] Extraindo transa√ß√£o de: "${text}"`);

      const prompt = TRANSACTION_USER_PROMPT_TEMPLATE(text, userContext?.categories);

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'system',
              content: getTransactionSystemPrompt(), // Gera prompt com data atual
            },
            { role: 'user', content: prompt },
          ],
          temperature: 0.1,
          max_tokens: 500,
        }),
      });

      if (!response.ok) {
        throw new Error(`Groq API error: ${response.statusText}`);
      }

      const data = await response.json();
      const resultText = data.choices[0]?.message?.content || '{}';

      // Extrair JSON
      const jsonMatch = resultText.match(/\{[\s\S]*\}/);
      const result = jsonMatch ? JSON.parse(jsonMatch[0]) : JSON.parse(resultText);

      const processingTime = Date.now() - startTime;

      this.logger.log(
        `‚úÖ [Groq] Transa√ß√£o extra√≠da em ${processingTime}ms ‚ö° - Valor: ${result.amount}`,
      );

      return result;
    } catch (error) {
      this.logger.error('[Groq] Erro ao extrair transa√ß√£o:', error);
      throw error;
    }
  }

  /**
   * Analisa imagem (Groq n√£o tem vision nativo, use Gemini ou OpenAI)
   */
  async analyzeImage(imageBuffer: Buffer, mimeType: string): Promise<TransactionData> {
    throw new Error('Groq n√£o suporta an√°lise de imagem. Use Google Gemini ou OpenAI Vision.');
  }

  /**
   * Transcreve √°udio usando Whisper GR√ÅTIS no Groq! üéâ
   * MUITO MAIS R√ÅPIDO que OpenAI e SEM CUSTO!
   */
  async transcribeAudio(audioBuffer: Buffer, mimeType: string): Promise<string> {
    try {
      const startTime = Date.now();
      this.logger.log(
        `[Groq Whisper] Transcrevendo √°udio GR√ÅTIS (${(audioBuffer.length / 1024).toFixed(2)} KB)`,
      );

      // Groq usa a mesma API que OpenAI para Whisper
      const formData = new FormData();
      const audioBlob = new Blob([audioBuffer as any], { type: mimeType });
      formData.append('file', audioBlob, 'audio.mp3');
      formData.append('model', 'whisper-large-v3');
      formData.append('language', 'pt');
      formData.append('response_format', 'text');

      const response = await fetch(`${this.baseUrl}/audio/transcriptions`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: formData,
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Groq Whisper API error: ${response.statusText} - ${errorText}`);
      }

      const transcription = await response.text();
      const processingTime = Date.now() - startTime;

      this.logger.log(`‚úÖ [Groq Whisper] √Åudio transcrito em ${processingTime}ms ‚ö° GR√ÅTIS! üÜì`);

      return transcription.trim();
    } catch (error) {
      this.logger.error('[Groq Whisper] Erro ao transcrever √°udio:', error);
      throw error;
    }
  }

  /**
   * Sugere categoria
   */
  async suggestCategory(description: string, userCategories: string[]): Promise<string> {
    try {
      this.logger.debug(`[Groq] Sugerindo categoria para: "${description}"`);

      let prompt = `Baseado na descri√ß√£o "${description}", sugira UMA categoria de gasto.`;

      if (userCategories.length > 0) {
        prompt += `\n\nCategorias dispon√≠veis: ${userCategories.join(', ')}`;
      }

      prompt += '\n\nRetorne APENAS o nome da categoria.';

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.model,
          messages: [{ role: 'user', content: prompt }],
          temperature: 0.2,
          max_tokens: 50,
        }),
      });

      const data = await response.json();
      const category = data.choices[0]?.message?.content?.trim() || 'Outros';

      this.logger.log(`‚úÖ [Groq] Categoria sugerida: ${category}`);

      return category;
    } catch (error) {
      this.logger.error('[Groq] Erro ao sugerir categoria:', error);
      return 'Outros';
    }
  }

  /**
   * Gera embedding vetorial
   * Groq n√£o suporta embeddings nativamente, usa fallback para OpenAI
   */
  async generateEmbedding(text: string): Promise<number[]> {
    throw new Error(
      'Groq n√£o suporta embeddings. Use OpenAI ou Google Gemini para RAG com embeddings.',
    );
  }
}
